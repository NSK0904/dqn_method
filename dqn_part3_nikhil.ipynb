{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b34043",
   "metadata": {},
   "source": [
    "# Test No. 2 For Best Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f41fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished after steps: 11\n",
      "\n",
      "*** Episode 0 ***                       \n",
      "Av.reward: [last 10]: 1.80, [last 100]: 0.18, [all]: 18.00                       \n",
      "epsilon: 0.99, frames_total: 18\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 10 ***                       \n",
      "Av.reward: [last 10]: 19.70, [last 100]: 2.15, [all]: 19.55                       \n",
      "epsilon: 0.90, frames_total: 215\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 20 ***                       \n",
      "Av.reward: [last 10]: 32.30, [last 100]: 5.38, [all]: 25.62                       \n",
      "epsilon: 0.77, frames_total: 538\n",
      "Elapsed time:  00:00:00\n",
      "\n",
      "*** Episode 30 ***                       \n",
      "Av.reward: [last 10]: 44.70, [last 100]: 9.85, [all]: 31.77                       \n",
      "epsilon: 0.61, frames_total: 985\n",
      "Elapsed time:  00:00:01\n",
      "\n",
      "*** Episode 40 ***                       \n",
      "Av.reward: [last 10]: 91.60, [last 100]: 19.01, [all]: 46.37                       \n",
      "epsilon: 0.39, frames_total: 1901\n",
      "Elapsed time:  00:00:02\n",
      "\n",
      "*** Episode 50 ***                       \n",
      "Av.reward: [last 10]: 237.80, [last 100]: 42.79, [all]: 83.90                       \n",
      "epsilon: 0.13, frames_total: 4279\n",
      "Elapsed time:  00:00:06\n",
      "\n",
      "*** Episode 60 ***                       \n",
      "Av.reward: [last 10]: 392.60, [last 100]: 82.05, [all]: 134.51                       \n",
      "epsilon: 0.03, frames_total: 8205\n",
      "Elapsed time:  00:00:11\n",
      "\n",
      "*** Episode 70 ***                       \n",
      "Av.reward: [last 10]: 702.70, [last 100]: 152.32, [all]: 214.54                       \n",
      "epsilon: 0.01, frames_total: 15232\n",
      "Elapsed time:  00:00:22\n",
      "SOLVED! After 73 episodes \n",
      "\n",
      "*** Episode 80 ***                       \n",
      "Av.reward: [last 10]: 1378.40, [last 100]: 290.16, [all]: 358.22                       \n",
      "epsilon: 0.01, frames_total: 29016\n",
      "Elapsed time:  00:00:49\n",
      "\n",
      "*** Episode 90 ***                       \n",
      "Av.reward: [last 10]: 3054.90, [last 100]: 595.65, [all]: 654.56                       \n",
      "epsilon: 0.01, frames_total: 59565\n",
      "Elapsed time:  00:01:49\n",
      "\n",
      "*** Episode 100 ***                       \n",
      "Av.reward: [last 10]: 928.00, [last 100]: 688.27, [all]: 681.63                       \n",
      "epsilon: 0.01, frames_total: 68845\n",
      "Elapsed time:  00:02:08\n",
      "\n",
      "*** Episode 110 ***                       \n",
      "Av.reward: [last 10]: 7482.40, [last 100]: 1434.54, [all]: 1294.32                       \n",
      "epsilon: 0.01, frames_total: 143669\n",
      "Elapsed time:  00:04:41\n",
      "\n",
      "*** Episode 120 ***                       \n",
      "Av.reward: [last 10]: 4356.40, [last 100]: 1866.95, [all]: 1547.38                       \n",
      "epsilon: 0.01, frames_total: 187233\n",
      "Elapsed time:  00:06:09\n",
      "\n",
      "*** Episode 130 ***                       \n",
      "Av.reward: [last 10]: 7525.20, [last 100]: 2615.00, [all]: 2003.70                       \n",
      "epsilon: 0.01, frames_total: 262485\n",
      "Elapsed time:  00:08:42\n",
      "\n",
      "*** Episode 140 ***                       \n",
      "Av.reward: [last 10]: 7054.10, [last 100]: 3311.25, [all]: 2361.89                       \n",
      "epsilon: 0.01, frames_total: 333026\n",
      "Elapsed time:  00:11:06\n",
      "\n",
      "*** Episode 150 ***                       \n",
      "Av.reward: [last 10]: 3814.40, [last 100]: 3668.91, [all]: 2458.08                       \n",
      "epsilon: 0.01, frames_total: 371170\n",
      "Elapsed time:  00:12:44\n",
      "\n",
      "*** Episode 160 ***                       \n",
      "Av.reward: [last 10]: 1015.80, [last 100]: 3731.23, [all]: 2368.50                       \n",
      "epsilon: 0.01, frames_total: 381328\n",
      "Elapsed time:  00:13:06\n",
      "\n",
      "*** Episode 170 ***                       \n",
      "Av.reward: [last 10]: 2072.70, [last 100]: 3868.23, [all]: 2351.20                       \n",
      "epsilon: 0.01, frames_total: 402055\n",
      "Elapsed time:  00:13:54\n",
      "\n",
      "*** Episode 180 ***                       \n",
      "Av.reward: [last 10]: 167.40, [last 100]: 3747.13, [all]: 2230.55                       \n",
      "epsilon: 0.01, frames_total: 403729\n",
      "Elapsed time:  00:13:58\n",
      "\n",
      "*** Episode 190 ***                       \n",
      "Av.reward: [last 10]: 90.60, [last 100]: 3450.70, [all]: 2118.51                       \n",
      "epsilon: 0.01, frames_total: 404635\n",
      "Elapsed time:  00:14:00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Average reward: 2038.34\n",
      "Average reward (last 100 episodes): 3400.10\n",
      "Solved after 73 episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished after steps: 146\n",
      "Finished after steps: 149\n",
      "Finished after steps: 143\n",
      "Finished after steps: 143\n",
      "Finished after steps: 148\n",
      "Finished after steps: 141\n",
      "Finished after steps: 145\n",
      "Finished after steps: 145\n",
      "Finished after steps: 150\n",
      "Finished after steps: 145\n"
     ]
    }
   ],
   "source": [
    "import torch                          \n",
    "import torch.nn as nn                 \n",
    "import torch.optim as optim           \n",
    "import gym                            \n",
    "import random                        \n",
    "import math                          \n",
    "import time                           \n",
    "\n",
    "import matplotlib.pyplot as plt       \n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "Tensor = torch.Tensor\n",
    "LongTensor = torch.LongTensor\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "seed_value = 23\n",
    "torch.manual_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_episodes = 200\n",
    "gamma = 0.99\n",
    "\n",
    "hidden_layer = 256\n",
    "\n",
    "replay_mem_size = 200000\n",
    "batch_size = 128\n",
    "\n",
    "egreedy = 1\n",
    "egreedy_final = 0.01\n",
    "egreedy_decay = 2000\n",
    "\n",
    "report_interval = 10\n",
    "score_to_solve = 195\n",
    "\n",
    "number_of_inputs = env.observation_space.shape[0]\n",
    "number_of_outputs = env.action_space.n \n",
    "\n",
    "def calculate_epsilon(steps_done):\n",
    "    epsilon = egreedy_final + (egreedy - egreedy_final) * \\\n",
    "              math.exp(-1. * steps_done / egreedy_decay )\n",
    "    return epsilon\n",
    "\n",
    "class NeuralNetwork(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(number_of_inputs,hidden_layer) \n",
    "        self.linear2 = nn.Linear(hidden_layer,number_of_outputs) \n",
    "        self.activation = nn.Tanh()\n",
    "        #self.activation = nn.ReLU()\n",
    "             \n",
    "    def forward(self, x):\n",
    "        output1 = self.linear1(x) \n",
    "        output1 = self.activation(output1)\n",
    "        output2 = self.linear2(output1)\n",
    "\n",
    "        return output2\n",
    "  \n",
    "class QNet_Agent(object):\n",
    "    def __init__(self):\n",
    "        self.nn = NeuralNetwork().to(device)\n",
    "        self.loss_func = nn.MSELoss()      \n",
    "        self.optimizer = optim.Adam(params=self.nn.parameters(), lr=learning_rate)\n",
    "\n",
    "        \n",
    "    def select_action(self,state,epsilon):\n",
    "        \n",
    "        random_for_egreedy = torch.rand(1)[0]\n",
    "        \n",
    "        if random_for_egreedy > epsilon: \n",
    "            \n",
    "            with torch.no_grad(): \n",
    "                \n",
    "                state = Tensor(state).to(device)\n",
    "                action_from_nn = self.nn(state) \n",
    "                action = torch.max(action_from_nn,0)[1]\n",
    "                action = action.item()\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def optimize(self):\n",
    "        \n",
    "        if (len(memory) < batch_size):\n",
    "            return\n",
    "        \n",
    "        state, action, new_state, reward, done = memory.sample(batch_size)\n",
    "        \n",
    "        state = Tensor(state).to(device) \n",
    "        new_state = Tensor(new_state).to(device)\n",
    "        reward = Tensor(reward).to(device)\n",
    "        action = LongTensor(action).to(device)\n",
    "        done = Tensor(done).to(device)\n",
    "\n",
    "        new_state_values = self.nn(new_state).detach()\n",
    "        max_new_state_values = torch.max(new_state_values, 1)[0]\n",
    "        target_value = reward + ( 1 - done ) * gamma * max_new_state_values\n",
    "  \n",
    "        predicted_value = self.nn(state).gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        loss = self.loss_func(predicted_value, target_value)\n",
    "    \n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    " \n",
    "class ExperienceReplay(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    " \n",
    "    def push(self, state, action, new_state, reward, done):\n",
    "        transition = (state, action, new_state, reward, done)\n",
    "        \n",
    "        if self.position >= len(self.memory): \n",
    "            self.memory.append(transition)\n",
    "        else:\n",
    "            self.memory[self.position] = transition\n",
    "        self.position = ( self.position + 1 ) % self.capacity\n",
    "        \n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return zip(*random.sample(self.memory, batch_size))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "        \n",
    "\n",
    "memory = ExperienceReplay(replay_mem_size)\n",
    "qnet_agent = QNet_Agent()\n",
    "qnet_agent.nn.eval()\n",
    "env = gym.make('CartPole-v1', render_mode = 'human')\n",
    "for episode in range(10):\n",
    "    state, _ = env.reset()\n",
    "    time.sleep(1.) \n",
    "    for step in range(10000):\n",
    "        env.render() \n",
    "        time.sleep(0.02) \n",
    "        action = qnet_agent.select_action(state, 0)\n",
    "        new_state, reward, done, _, _ = env.step(action)\n",
    "        state = new_state\n",
    "        if done:\n",
    "            print('Finished after steps:', step)\n",
    "            break\n",
    "    \n",
    "    break\n",
    "env.close()\n",
    "env.env.close()\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "qnet_agent.nn.train()\n",
    "\n",
    "steps_total = [] \n",
    "\n",
    "frames_total = 0 \n",
    "solved_after = 0 \n",
    "solved = False\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "\n",
    "    state, _ = env.reset()\n",
    "    \n",
    "    step = 0 \n",
    "\n",
    "    while True: \n",
    "        \n",
    "        step += 1 \n",
    "        frames_total += 1 \n",
    "        \n",
    "        epsilon = calculate_epsilon(frames_total) \n",
    "        \n",
    "        #action = env.action_space.sample()\n",
    "        action = qnet_agent.select_action(state, epsilon) \n",
    "        \n",
    "        new_state, reward, done, _, _ = env.step(action) \n",
    "\n",
    "        memory.push(state, action, new_state, reward, done) \n",
    "        qnet_agent.optimize() \n",
    "        \n",
    "        state = new_state \n",
    "         \n",
    "        if done: \n",
    "            steps_total.append(step) \n",
    "            \n",
    "            mean_reward_100 = sum(steps_total[-100:])/100\n",
    "            \n",
    "            if (mean_reward_100 > score_to_solve and solved == False):\n",
    "                print(\"SOLVED! After %i episodes \" % i_episode)\n",
    "                solved_after = i_episode\n",
    "                solved = True\n",
    "            \n",
    "            if (i_episode % report_interval == 0):\n",
    "                \n",
    "                \n",
    "                \n",
    "                print(\"\\n*** Episode %i *** \\\n",
    "                      \\nAv.reward: [last %i]: %.2f, [last 100]: %.2f, [all]: %.2f \\\n",
    "                      \\nepsilon: %.2f, frames_total: %i\" \n",
    "                  % \n",
    "                  ( i_episode,\n",
    "                    report_interval,\n",
    "                    sum(steps_total[-report_interval:])/report_interval,\n",
    "                    mean_reward_100,\n",
    "                    sum(steps_total)/len(steps_total),\n",
    "                    epsilon,\n",
    "                    frames_total\n",
    "                          ) \n",
    "                  ) \n",
    "                  \n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(\"Elapsed time: \", time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n",
    "\n",
    "\n",
    "            break\n",
    "        \n",
    "state_dict = qnet_agent.nn.state_dict()\n",
    "torch.save(state_dict, 'dqn_er_best14.pth')\n",
    "\n",
    "\n",
    "print(\"\\n\\n\\n\\nAverage reward: %.2f\" % (sum(steps_total)/num_episodes))\n",
    "print(\"Average reward (last 100 episodes): %.2f\" % (sum(steps_total[-100:])/100))\n",
    "if solved:\n",
    "    print(\"Solved after %i episodes\" % solved_after)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.title(\"Rewards\")\n",
    "plt.bar(torch.arange(len(steps_total)), steps_total, alpha=0.6, color='green', width=5)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "env.close()\n",
    "env.env.close()\n",
    "\n",
    "\n",
    "state_dict = torch.load('dqn_er_best14.pth')\n",
    "qnet_agent.nn.load_state_dict(state_dict)\n",
    "qnet_agent.nn.eval()\n",
    "env = gym.make('CartPole-v1', render_mode = 'human')\n",
    "for episode in range(10):\n",
    "    state, _ = env.reset()\n",
    "    time.sleep(1.) \n",
    "    for step in range(10000):\n",
    "        env.render() \n",
    "        time.sleep(0.02) \n",
    "        action = qnet_agent.select_action(state, 0)\n",
    "        new_state, reward, done, _, _ = env.step(action)\n",
    "        state = new_state\n",
    "        if done:\n",
    "            print('Finished after steps:', step)\n",
    "            break\n",
    "env.close()\n",
    "env.env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1b1f8",
   "metadata": {},
   "source": [
    "# Explanation of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5bf0bf",
   "metadata": {},
   "source": [
    "Key points from results:\n",
    "\n",
    "The algorithm solved the problem after 73 episodes, which is little bit slower compared to the previous two tests.\n",
    "The average reward across all episodes was 2038.34 which is a huge rise from the previous test.\n",
    "The average reward across the last 100 episodes was 3400.10.\n",
    "\n",
    "Comparing with the previous tests:\n",
    "\n",
    "This test results solved the problem in 73 episodes, indicating that the algorithm performed well.\n",
    "The set of results had a higher average reward across all episodes (2038.34 compared to 1330.33 and 383.64), indicating that the algorithm performed best overall.\n",
    "\n",
    "This set of results also had a higher average reward across the last 100 episodes (3400.10 compared to 1657.47 and 383.64), indicating that the algorithm's performance improved very well over time.\n",
    "\n",
    "In general, this set of results shows that the algorithm performed best than the previous tests and was able to solve the problem more efficiently than the first set of results. It had higher average rewards across all episodes and the last 100 episodes. It did take around 14 minutes to solve the problem and the main reason to this could be the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f8142",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff96f5",
   "metadata": {},
   "source": [
    "The code used is a reinforcement learning algorithm that uses a Q-learning approach to train an agent to play the CartPole-v1 game from the gym library. The Q-learning approach is implemented using a neural network to estimate the Q-value function, and experience replay to store and sample the transitions of the agent from the environment. The algorithm also uses an epsilon-greedy policy to balance exploration and exploitation during the training process. The training process is stopped if the agent achieves an average score of 195 over 100 consecutive episodes, which is the score needed to solve the CartPole-v1 game. The final output of the algorithm is the number of steps taken by the agent to solve the game.\n",
    "\n",
    "Apart from the intial test, I did 2 different tests with different hyperparameter values to compare results, and in general changing the values of hyperparameters affected the results hugely. However all 3 tests were successful as they were able to solve the problem and the agent was able to achieve an average score of 195 over 100 consecutive episodes for all 3 tests. The second test was able to solve the problem in minimal number of episodes (35) however the third test which took a relatively longer time to solve produced an average reward of 2038 and 3400 for average reward (last 100 episodes) which is an incredible score. \n",
    "\n",
    "In conclusion, I was able to successfully complete the task, by adding comments, changing hyperparameter values to obtain the best results. The following are the best hyperparameters for best results from all 3 tests:\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_episodes = 150\n",
    "gamma = 0.99\n",
    "\n",
    "hidden_layer = 128\n",
    "\n",
    "replay_mem_size = 100000\n",
    "batch_size = 64\n",
    "\n",
    "egreedy = 0.99\n",
    "egreedy_final = 0.05\n",
    "egreedy_decay = 1000\n",
    "\n",
    "In future there is still room for improvement as more different tests could be performed which could lead to more critical analysis and comparisons. This may be time consuming, however it is certain that changing the parameters greatly affects the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
